{"backend_state":"running","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":46039040},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1595254580045,"exec_count":17,"id":"2bfb8d","input":"from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\n\n\n\nimport string\nimport re\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","kernel":"python3","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"2bfb8d","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":1,"start":1595254580041,"state":"done","type":"cell"}
{"cell_type":"code","end":1595254637992,"exec_count":24,"id":"b7efae","input":"SOS_token = 0\nEOS_token = 1\n\n!wget https://download.pytorch.org/tutorial/data.zip\n!unzip data.zip > /dev/null\n    \nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {} # \n        self.word2count = {} # words counter\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # Count SOS and EOS\n\n\n    def addSentence(self, sentence):\n        # Add words splitting the sentence by space\n        # YOUR CODE HERE\n        #raise NotImplementedError()\n        for word in sentence.split(' '):\n            self.addWord(word)\n    def addWord(self, word):\n        # Update self.word2index, self.word2count, self.n_words\n        # YOUR CODE HERE\n        #raise NotImplementedError()\n        if word in self.word2index:\n            self.word2count[word] += 1\n        else:\n            self.word2count[word] = 1\n            self.word2index[word] = self.n_words\n            self.index2word[self.n_words] = word\n            self.n_words += 1","kernel":"python3","metadata":{"nbgrader":{"cell_type":"code","checksum":"91c0be0107d09fe511556586c02fc2bd","grade":false,"grade_id":"b7efae","locked":false,"schema_version":3,"solution":true,"task":false}},"output":{"0":{"name":"stdout","text":"--2020-07-20 14:17:17--  https://download.pytorch.org/tutorial/data.zip\r\nResolving download.pytorch.org (download.pytorch.org)... 13.249.71.29, 13.249.71.42, 13.249.71.40, ...\r\nConnecting to download.pytorch.org (download.pytorch.org)|13.249.71.29|:443... connected.\r\n"},"1":{"name":"stdout","text":"HTTP request sent, awaiting response... 200 OK\r\nLength: 2882130 (2.7M) [application/zip]\r\nSaving to: ‘data.zip’\r\n\r\n\rdata.zip              0%[                    ]       0  --.-KB/s               "},"2":{"name":"stdout","text":"\rdata.zip            100%[===================>]   2.75M  18.2MB/s    in 0.2s    \r\n\r\n2020-07-20 14:17:17 (18.2 MB/s) - ‘data.zip’ saved [2882130/2882130]\r\n\r\n"}},"pos":2,"start":1595254637369,"state":"done","type":"cell"}
{"cell_type":"code","end":1595254640858,"exec_count":25,"id":"2fea4b","input":"test_lang = Lang('test')\ntest_lang.addSentence('Hello, World!')\nassert test_lang.n_words == 4\nassert test_lang.word2index == {'Hello,': 2, 'World!': 3}\nassert test_lang.word2count == {'Hello,': 1, 'World!': 1}","kernel":"python3","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":true,"grade_id":"2fea4b","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"pos":3,"start":1595254640856,"state":"done","type":"cell"}
{"cell_type":"code","end":1595254642085,"exec_count":26,"id":"e60806","input":"# Turn a Unicode string to plain ASCII, thanks to\n# https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n# Lowercase, trim, and remove non-letter characters\n\n\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n    return s","kernel":"python3","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"e60806","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":4,"start":1595254642081,"state":"done","type":"cell"}
{"cell_type":"code","end":1595254643344,"exec_count":27,"id":"15a5d4","input":"def readLangs(lang1, lang2, reverse=False):\n    print(\"Reading lines...\")\n\n    # Read the file and split into lines\n    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n        read().strip().split('\\n')\n\n    # Split every line into pairs and normalize\n    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n\n    # Reverse pairs, make Lang instances\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        input_lang = Lang(lang2)\n        output_lang = Lang(lang1)\n    else:\n        input_lang = Lang(lang1)\n        output_lang = Lang(lang2)\n\n    return input_lang, output_lang, pairs","kernel":"python3","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"15a5d4","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":5,"start":1595254643335,"state":"done","type":"cell"}
{"cell_type":"code","end":1595254644418,"exec_count":28,"id":"49e7f8","input":"MAX_LENGTH = 10\n\neng_prefixes = (\n    \"i am \", \"i m \",\n    \"he is\", \"he s \",\n    \"she is\", \"she s \",\n    \"you are\", \"you re \",\n    \"we are\", \"we re \",\n    \"they are\", \"they re \"\n)\n\n\ndef filterPair(p):\n    return len(p[0].split(' ')) < MAX_LENGTH and \\\n        len(p[1].split(' ')) < MAX_LENGTH and \\\n        p[1].startswith(eng_prefixes)\n\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]","kernel":"python3","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"49e7f8","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":6,"start":1595254644416,"state":"done","type":"cell"}
{"cell_type":"code","end":1595255114890,"exec_count":34,"id":"19371d","input":"assert indexesFromSentence(output_lang, 'master driver') == [975, 977]","kernel":"python3","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":true,"grade_id":"19371d","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"pos":9,"start":1595255114888,"state":"done","type":"cell"}
{"cell_type":"code","end":1595255977493,"exec_count":35,"id":"072b6c","input":"def prepareData(lang1, lang2, reverse=False):\n    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n    print(\"Read %s sentence pairs\" % len(pairs))\n    pairs = filterPairs(pairs)\n    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs\n\n# Uncomment if data does not exists\n# !wget https://download.pytorch.org/tutorial/data.zip\n# !unzip data.zip > /dev/null\n\ninput_lang, output_lang, pairs = prepareData('eng', 'fra', True)\nprint(random.choice(pairs))","kernel":"python3","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"072b6c","locked":true,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"name":"stdout","text":"Reading lines...\n"},"1":{"name":"stdout","text":"Read 135842 sentence pairs\nTrimmed to 10599 sentence pairs\nCounting words...\nCounted words:\nfra 4345\neng 2803\n['je suis content de vous voir .', 'i m glad to meet you .']\n"}},"pos":7,"start":1595255972607,"state":"done","type":"cell"}
{"cell_type":"code","end":1595255980932,"exec_count":36,"id":"d3c5ff","input":"def indexesFromSentence(lang, sentence):\n    # split sentence by space and convert words to indices\n    # YOUR CODE HERE\n    #raise NotImplementedError()\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)","kernel":"python3","metadata":{"nbgrader":{"cell_type":"code","checksum":"6921fb84bbc0daf4d855b3614684ef6b","grade":false,"grade_id":"d3c5ff","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":8,"start":1595255980930,"state":"done","type":"cell"}
{"cell_type":"code","end":1595256004200,"exec_count":37,"id":"dbc772","input":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(input_size, hidden_size) # Special learnable layer which converts tensor of word indices to tensor of hidden size\n        # Define your RNN here\n        # YOUR CODE HERE\n        #raise NotImplementedError()\n        self.gru = nn.GRU(hidden_size, hidden_size)\n        \n    def forward(self, input, hidden):\n        # HINT 1: input is single sentence of word indexes\n        # HINT 2: PyTorch RNNs takes [seq_len, batch_size, hidden_size] tensor as input\n        # YOUR CODE HERE\n        #raise NotImplementedError()\n        output = self.embedding(input)\n        output, hidden = self.gru(input, hidden)\n        return output, hidden\n\n    def initHidden(self):\n\n        return torch.zeros(1, 1, self.hidden_size, device=device)","kernel":"python3","metadata":{"nbgrader":{"cell_type":"code","checksum":"694ca9f38bb0711a8ec15eac04928fe0","grade":false,"grade_id":"dbc772","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":10,"start":1595256004197,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"047580","input":"evaluateRandomly(encoder, decoder)","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"047580","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":19,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"2c20d9","input":"hidden_size = 256\nencoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\ndecoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n\ntrainIters(encoder, decoder, 75000, print_every=5000)","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"2c20d9","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":18,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"361d6c","input":"def evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words = evaluate(encoder, decoder, pair[0])\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"361d6c","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":17,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"63a789","input":"def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH,teacher_forcing_ratio=0.5):\n    encoder_hidden = encoder.initHidden()\n\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n\n    loss = 0\n\n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(\n            input_tensor[ei], encoder_hidden)\n\n    decoder_input = torch.tensor([[SOS_token]], device=device)\n\n    decoder_hidden = encoder_hidden\n\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    for di in range(target_length):\n        decoder_output, decoder_hidden = decoder(\n            decoder_input, decoder_hidden)\n        if use_teacher_forcing: # Teacher forcing: Feed the target as the next decoder input\n            # YOUR CODE HERE\n            raise NotImplementedError()\n        else:                   # Without teacher forcing: use its own predictions as the next input\n            # YOUR CODE HERE\n            raise NotImplementedError()\n        loss += criterion(decoder_output, target_tensor[di])\n        # Stop if terminate token (EOS) is generated\n        # YOUR CODE HERE\n        raise NotImplementedError()\n\n    # Perform gradient step\n    # YOUR CODE HERE\n    raise NotImplementedError()\n    \n    return loss.item() / target_length","metadata":{"nbgrader":{"cell_type":"code","checksum":"8e745bef7f55558f102d841510134b25","grade":false,"grade_id":"63a789","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"8d450b","input":"def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n\n    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n    training_pairs = [tensorsFromPair(random.choice(pairs))\n                      for i in range(n_iters)]\n    criterion = nn.NLLLoss()\n\n    for iter in range(1, n_iters + 1):\n        training_pair = training_pairs[iter - 1]\n        input_tensor = training_pair[0]\n        target_tensor = training_pair[1]\n\n        loss = train(input_tensor, target_tensor, encoder,\n                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if iter % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n                                         iter, iter / n_iters * 100, print_loss_avg))\n\n        if iter % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    showPlot(plot_losses)\n","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"8d450b","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":14,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"bb686a","input":"","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":true,"grade_id":"bb686a","locked":true,"points":3,"schema_version":3,"solution":false,"task":false}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"ce4830","input":"def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n    with torch.no_grad():\n        input_tensor = tensorFromSentence(input_lang, sentence)\n        input_length = input_tensor.size()[0]\n        encoder_hidden = encoder.initHidden()\n\n\n        decoded_words = []\n        # Translate the sentence. Substitute EOS_token with \"<EOS>\" and append to the end of decoded_words\n        \n        # YOUR CODE HERE\n        raise NotImplementedError()\n        return decoded_words","metadata":{"nbgrader":{"cell_type":"code","checksum":"16e23290802881816d1a947870bf8287","grade":false,"grade_id":"ce4830","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":16,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"e9d29b","input":"import time\nimport math\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"e9d29b","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"fc1a8f","input":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"fc1a8f","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":15,"type":"cell"}
{"cell_type":"code","exec_count":33,"id":"cf9459","input":"class DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        \n        self.embedding =nn.Embedding(output_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n        # YOUR CODE HERE\n        #raise NotImplementedError()\n\n    def forward(self, input, hidden):\n        # YOUR CODE HERE\n        #raise NotImplementedError()\n        input = self.embedding(input)\n        output, hidden = self.gru(input, hidden)\n        output = self.out(output)\n        output = F.log_softmax(output,1)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","kernel":"python3","metadata":{"nbgrader":{"cell_type":"code","checksum":"6a477999f4341f82594e4e56c7821c17","grade":false,"grade_id":"cf9459","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":11,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"4c72ec","input":"# Machine translation using RNN\nThe code is taken from [PyTorch examples](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n\n![](https://pytorch.org/tutorials/_images/seq2seq.png)","pos":0,"type":"cell"}
{"id":0,"time":1595316950793,"type":"user"}
{"last_load":1595253757364,"type":"file"}