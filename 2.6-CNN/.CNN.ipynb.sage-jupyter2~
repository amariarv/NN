{"backend_state":"running","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":46039040},"metadata":{"accelerator":"GPU","colab":{"name":"seminar_convnets.ipynb","provenance":[],"version":"0.3.2"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"059fed","input":"import os\nimport torch, torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom tiny_img import download_tinyImg200\nif not os.path.exists('./tiny-imagenet-200/'):\n    download_tinyImg200('.')\n    \ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"colab_type":"code","id":"umUCOiHFrYDk","outputId":"4703515a-c483-4375-a7ea-1c2bf9260426"},"pos":3,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"2ea31c","input":"model.train(False) \ntest_batch_acc = []\n\nfor X_batch, y_batch in DataLoader(test_dataset, batch_size=batch_size):\n    logits = model(torch.as_tensor(X_batch, device=device, dtype=torch.float32))\n    y_pred = logits.max(1)[1].data\n    test_batch_acc.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n\n\ntest_accuracy = np.mean(test_batch_acc)\n    \nprint(\"Final results:\")\nprint(\"  test accuracy:\\t\\t{:.2f} %\".format(\n    test_accuracy * 100))\n\nif test_accuracy * 100 > 70:\n    print(\"U'r freakin' amazin'!\")\nelif test_accuracy * 100 > 50:\n    print(\"Achievement unlocked: 110lvl Warlock!\")\nelif test_accuracy * 100 > 40:\n    print(\"Achievement unlocked: 80lvl Warlock!\")\nelif test_accuracy * 100 > 30:\n    print(\"Achievement unlocked: 70lvl Warlock!\")\nelif test_accuracy * 100 > 20:\n    print(\"Achievement unlocked: 60lvl Warlock!\")\nelse:\n    print(\"We need more magic! Follow instructons below\")","metadata":{"colab":{},"colab_type":"code","id":"0iKXTHsCrYFG","outputId":"2521b0c1-877e-4350-e207-075537737ea3"},"pos":16,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"440dbd","input":"from torchsummary import summary\nsummary(model.cuda(), (3, 64, 64))","metadata":{"colab":{},"colab_type":"code","id":"PlnANpccrYFk"},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"4a009f","input":"import torch, torch.nn as nn\nimport torch.nn.functional as F\n\n# a special module that converts [batch, channel, w, h] to [batch, units]\nclass Flatten(nn.Module):\n    def forward(self, input):\n        return input.view(input.shape[0], -1)","metadata":{"colab":{},"colab_type":"code","id":"dOz-ioB7rYEQ"},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"4a56e1","input":"model = nn.Sequential()\n\n<describe convnet here>\n\nmodel.add_module('dense1_logits', nn.Linear(<...>, 200)) # logits for 200 classes","metadata":{"colab":{},"colab_type":"code","id":"XRTq8rxPrYFU"},"pos":18,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"504fe0","input":"def compute_loss(X_batch, y_batch):\n    X_batch = torch.as_tensor(X_batch, dtype=torch.float32, device=device)\n    y_batch = torch.as_tensor(y_batch, dtype=torch.int64, device=device)\n    logits = model(X_batch)\n    return F.cross_entropy(logits, y_batch).mean()","metadata":{"colab":{},"colab_type":"code","id":"Idf0vTKBrYEq"},"pos":11,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"5c381c","input":"model.train(False) # disable dropout / use averages for batch_norm\ntest_batch_acc = []\n\nfor X_batch, y_batch in DataLoader(test_dataset, batch_size=batch_size):\n    logits = model(torch.as_tensor(X_batch, device='cuda', dtype=torch.float32))\n    y_pred = logits.max(1)[1].data\n    test_batch_acc.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n\n\ntest_accuracy = np.mean(test_batch_acc)\n    \nprint(\"Final results:\")\nprint(\"  test accuracy:\\t\\t{:.2f} %\".format(\n    test_accuracy * 100))\n\nif test_accuracy * 100 > 70:\n    print(\"U'r freakin' amazin'!\")\nelif test_accuracy * 100 > 50:\n    print(\"Achievement unlocked: 110lvl Warlock!\")\nelif test_accuracy * 100 > 40:\n    print(\"Achievement unlocked: 80lvl Warlock!\")\nelif test_accuracy * 100 > 30:\n    print(\"Achievement unlocked: 70lvl Warlock!\")\nelif test_accuracy * 100 > 20:\n    print(\"Achievement unlocked: 60lvl Warlock!\")\nelse:\n    print(\"We need more magic! Follow instructons below\")","metadata":{"colab":{},"colab_type":"code","id":"B0_7ihSnrYF2"},"pos":23,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"75783e","input":"import numpy as np\nimport time\n\nnum_epochs = 100    # total number of full passes over data until training finishes\nbatch_size = 64     # number of images in one minibatch\n\nfor epoch in range(100):\n    start_time = time.time()\n    model.train(True) # enable dropout / batch_norm training behavior\n    for (X_batch, y_batch) in DataLoader(train_dataset, batch_size=batch_size, shuffle=True):\n        # train on batch\n        loss = compute_loss(X_batch, y_batch)\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        train_loss.append(loss.cpu().data.numpy())\n    \n    model.train(False) # disable dropout / use averages for batch_norm\n    for X_batch, y_batch in torch.utils.data.DataLoader(val_dataset, batch_size=batch_size):\n        logits = model(torch.as_tensor(X_batch, device=device, dtype=torch.float32))\n        y_pred = logits.max(1)[1].data\n        val_accuracy.append(np.mean((y_batch.cpu() == y_pred.cpu()).numpy()))\n\n    \n    # Then we print the results for this epoch:\n    print(\"Epoch {} of {} took {:.3f}s\".format(\n        epoch + 1, num_epochs, time.time() - start_time))\n    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n        np.mean(train_loss[-len(train_dataset) // batch_size :])))\n    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n        np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":127},"colab_type":"code","id":"QTxZDwcZrYE8","outputId":"c3997a80-e4f6-487d-948a-e4b3038c4094"},"pos":14,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"9aca26","input":"num_epochs = 100    # total number of full passes over data until training finishes\nbatch_size = 64     # number of images in one minibatch\n\nfor epoch in range(100):\n    start_time = time.time()\n    model.train(True) # enable dropout / batch_norm training behavior\n    for (X_batch, y_batch) in DataLoader(train_dataset, batch_size=batch_size, shuffle=True):\n        # train on batch\n        loss = compute_loss(X_batch, y_batch)\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        train_loss.append(loss.cpu().data.numpy())\n    \n    model.train(False) # disable dropout / use averages for batch_norm\n    for X_batch, y_batch in torch.utils.data.DataLoader(val_dataset, batch_size=batch_size):\n        logits = model(torch.as_tensor(X_batch, device=device, dtype=torch.float32))\n        y_pred = logits.max(1)[1].data\n        val_accuracy.append(np.mean((y_batch.cpu() == y_pred.cpu()).numpy()))\n\n    \n    # Then we print the results for this epoch:\n    print(\"Epoch {} of {} took {:.3f}s\".format(\n        epoch + 1, num_epochs, time.time() - start_time))\n    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n        np.mean(train_loss[-len(train_dataset) // batch_size :])))\n    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n        np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100))","metadata":{"colab":{},"colab_type":"code","id":"pMUxrwGvrYFu"},"pos":22,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"9b0625","input":"model = nn.Sequential()\n\n# reshape from \"images\" to flat vectors\nmodel.add_module('flatten', Flatten())\n\n# dense \"head\"\nmodel.add_module('dense1', nn.Linear(3 * 64 * 64, 1064))\nmodel.add_module('dense2', nn.Linear(1064, 512))\nmodel.add_module('dropout0', nn.Dropout(0.05)) \nmodel.add_module('dense3', nn.Linear(512, 256))\nmodel.add_module('dropout1', nn.Dropout(0.05))\nmodel.add_module('dense4', nn.Linear(256, 64))\nmodel.add_module('dropout2', nn.Dropout(0.05))\nmodel.add_module('dense1_relu', nn.ReLU())\nmodel.add_module('dense2_logits', nn.Linear(64, 200)) # logits for 200 classes\n\nmodel = model.to(device=device)","metadata":{"colab":{},"colab_type":"code","id":"f43dEPxzrYEb"},"pos":9,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"ef464f","input":"opt = torch.optim.SGD(model.parameters(), lr=0.01)\n\ntrain_loss = []\nval_accuracy = []","metadata":{"colab":{},"colab_type":"code","id":"DqIK0aZyrYFd"},"pos":19,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"f50158","input":"import matplotlib.pyplot as plt\n%matplotlib inline\nfor i in range(10):\n    xi, yi = train_dataset[i]\n    plt.imshow(xi.data.numpy().transpose(1, 2, 0))\n    plt.title('class = %i' % yi)\n    plt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","id":"h7nHj64grYD9","outputId":"5bab45b9-fcea-4360-a9bd-fee9be91bee9"},"pos":5,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"fac661","input":"dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/train', transform=transforms.ToTensor())\ntest_dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/val', transform=transforms.ToTensor())\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [80000, 20000])\ntest_dataset, val_dataset = torch.utils.data.random_split(val_dataset, [10000, 10000])","metadata":{"colab":{},"colab_type":"code","id":"tvz-gycUrYD1"},"pos":4,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"fb9f0b","input":"opt = torch.optim.SGD(model.parameters(), lr=0.01)\n\ntrain_loss = []\nval_accuracy = []","metadata":{"colab":{},"colab_type":"code","id":"I0RGtIAirYE0"},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"fd8a23","input":"# if you're running in colab,\n# 1. go to Runtime -> Change Runtimy Type -> GPU\n# 2. Run this\n!wget https://raw.githubusercontent.com/yandexdataschool/Practical_DL/spring2019/week03_convnets/tiny_img.py -O tiny_img.py","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"colab_type":"code","id":"Rs909MGPrYDK","outputId":"2cbaab62-69fb-4e45-b4fb-e129237e78c4"},"pos":1,"type":"cell"}
{"cell_type":"markdown","id":"068db4","input":"# Deep learning for computer vision\n\n\nThis notebook will teach you to build and train convolutional networks for image recognition. Brace yourselves.","metadata":{"colab_type":"text","id":"wBE9GIubrYDC"},"pos":0,"type":"cell"}
{"cell_type":"markdown","id":"16895f","input":"Don't wait for full 100 epochs. You can interrupt training after 5-20 epochs once validation accuracy stops going up.\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n### Final test","metadata":{"colab_type":"text","id":"OJy3BBGKrYFE"},"pos":15,"type":"cell"}
{"cell_type":"markdown","id":"4ead94","input":"### Training on minibatches\n* We got 100k images, that's way too many for a full-batch SGD. Let's train on minibatches instead\n* Below is a function that splits the training sample into minibatches","metadata":{"colab_type":"text","id":"qCtLM639rYEw"},"pos":12,"type":"cell"}
{"cell_type":"markdown","id":"59750f","input":"# Building a network\n\nSimple neural networks with layers applied on top of one another can be implemented as `torch.nn.Sequential` - just add a list of pre-built modules and let it train.","metadata":{"colab_type":"text","id":"MM8T9MISrYEM"},"pos":6,"type":"cell"}
{"cell_type":"markdown","id":"9a941b","input":"Let's start with a dense network for our baseline:","metadata":{"colab_type":"text","id":"jZxtxzt0rYEY"},"pos":8,"type":"cell"}
{"cell_type":"markdown","id":"a0cb5a","input":"As in our basic tutorial, we train our model with negative log-likelihood aka crossentropy.","metadata":{"colab_type":"text","id":"Xk4XvZcBrYEk"},"pos":10,"type":"cell"}
{"cell_type":"markdown","id":"b999b4","input":"## Task: small convolution net\n\nLet's create a mini-convolutional network with roughly such architecture:\n* Input layer\n* 3x3 convolution with 128 filters and _ReLU_ activation\n* 2x2 pooling (or set previous convolution stride to 3)\n* Flatten\n* Dense layer with 1024 neurons and _ReLU_ activation\n* 30% dropout\n* Output dense layer.\n\n\n__Convolutional layers__ in torch are just like all other layers, but with a specific set of parameters:\n\n__`...`__\n\n__`model.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3)) # convolution`__\n\n__`model.add_module('pool1', nn.MaxPool2d(2)) # max pooling 2x2`__\n\n__`...`__\n\n\nOnce you're done (and compute_loss no longer raises errors), train it with __Adam__ optimizer with default params (feel free to modify the code above).\n\nIf everything is right, you should get at least __16%__ validation accuracy.\n\n__HACK_OF_THE_DAY__ :the number of channels must be in the order of the number of class_labels","metadata":{"colab_type":"text","id":"SmFLssyIrYFS"},"pos":17,"type":"cell"}
{"cell_type":"markdown","id":"c05cb8","input":"```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n```\n\n__Hint:__ If you don't want to compute shapes by hand, just plug in any shape (e.g. 1 unit) and run compute_loss. You will see something like this:\n\n__`RuntimeError: size mismatch, m1: [5 x 1960], m2: [1 x 64] at /some/long/path/to/torch/operation`__\n\nSee the __1960__ there? That's your actual input shape.\n","metadata":{"colab_type":"text","id":"MB3rnh6-rYF9"},"pos":24,"type":"cell"}
{"cell_type":"markdown","id":"d836e8","input":"## Train it ##","metadata":{"colab_type":"text","id":"31NP8etbrYFr"},"pos":21,"type":"cell"}
{"cell_type":"markdown","id":"eaa745","input":"# Tiny ImageNet dataset\nThis week, we shall focus on the image recognition problem on Tiny Image Net dataset\n* 100k images of shape 3x64x64\n* 200 different classes: snakes, spiders, cats, trucks, grasshoppers, gulls, etc.\n","metadata":{"colab_type":"text","id":"ltPwgnpVrYDg"},"pos":2,"type":"cell"}
{"id":0,"time":1595242053118,"type":"user"}
{"last_load":1595242053289,"type":"file"}