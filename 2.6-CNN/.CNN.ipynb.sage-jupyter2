{"args":["--to","script"],"start":1595696294401,"state":"done","time":1595696295589,"type":"nbconvert"}
{"attachments":{"image.png":{"type":"sha1","value":"4c79c1bd51890138c8173e4de2d1a089c9e57636"}},"cell_type":"markdown","id":"068db4","input":"# Deep learning for computer vision\n\n![image.png](attachment:image.png)\n\nThis notebook will teach you to build and train convolutional networks for image recognition.","metadata":{"colab_type":"text","id":"wBE9GIubrYDC"},"pos":0,"type":"cell"}
{"attachments":{"image.png":{"type":"sha1","value":"e51a5077c4af39778916ab6ec684eb09bf088a63"}},"cell_type":"markdown","id":"ca0982","input":"Hopefully you've managed to succeed. If not, you may always come back to this task after looking at at more advanced topics, e.g. regularization and batch normalization.\n\n**Question**: What are your model's weaknesses and how might they be improved?\n\n**Answer**: This model seems to do best on boots rather than coats. For example, it does best on the Sandal class and worst on the Shirt class. Maybe it's because Shirts vary in size and so it would improve this model if you could increase the number of shirt images in the first place or perhaps if one added another convolutional layer to detect finer patterns in these images. One could also experiment with a smaller learning rate so that the model takes small steps in the right direction as it is training.\n\nImages with correct and predicted labels like the one below are stored in Tensorboard images during the training.\n![image.png](attachment:image.png)","pos":32,"type":"cell"}
{"backend_state":"running","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":46096384},"metadata":{"accelerator":"GPU","celltoolbar":"Create Assignment","colab":{"name":"seminar_convnets.ipynb","provenance":[],"version":"0.3.2"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"059fed","input":"def get_free_gpu():\n    from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo, nvmlDeviceGetCount\n    nvmlInit()\n\n    return np.argmax([\n        nvmlDeviceGetMemoryInfo(nvmlDeviceGetHandleByIndex(i)).free\n        for i in range(nvmlDeviceGetCount())\n    ])\n\nif torch.cuda.is_available():\n    cuda_id = get_free_gpu()\n    device = 'cuda:%d' % (get_free_gpu(), )\n    print('Selected %s' % (device, ))\nelse:\n    device = 'cpu'\n    print('WARNING: using cpu!')\n\n### please, don't remove the following line\nx = torch.tensor([1], dtype=torch.float32).to(device)","pos":7,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"1b84b9","input":"from IPython.core.display import HTML\nfrom markdown import markdown\n\nmarkdown_string = f\"Tensorboard URL: [https://mlhep.coresearch.club/{os.environ['COCALC_PROJECT_ID']}/server/6006/](https://mlhep.coresearch.club/{os.environ['COCALC_PROJECT_ID']}/server/6006/)\"\n\nHTML(\"<p>{}</p>\".format(markdown(markdown_string)))","pos":20,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"28fbc0","input":"","pos":33,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"2ea31c","input":"def test_model(model, writer):\n    class_correct = list(0. for i in range(10))\n    class_total = list(0. for i in range(10))\n    test_accuracy = 0\n    cpu_model = model.to('cpu')\n    cpu_model.train(False)\n    with torch.no_grad():\n        for X_batch, y_batch in DataLoader(ds_test, batch_size=len(ds_test)):\n            output = cpu_model(X_batch)\n            test_accuracy = 100 * accuracy(y_batch, output)\n            _, pred = torch.max(output, 1)\n            correct_tensor = pred.eq(y_batch.data.view_as(pred))\n            correct = np.squeeze(correct_tensor.cpu().numpy())\n            for i in range(len(y_batch)):\n                label = y_batch.data[i]\n                class_correct[label] += correct[i].item()\n                class_total[label] += 1\n\n\n    print(\"Final results:\")\n    print(f\"  test accuracy:\\t\\t{test_accuracy:.2f}\")\n\n    if test_accuracy > 98:\n        print(\"U'r freakin' amazin'!\")\n    elif test_accuracy > 95:\n        print(\"Achievement unlocked: 110lvl Warlock!\")\n    elif test_accuracy > 90:\n        print(\"Achievement unlocked: 80lvl Warlock!\")\n    elif test_accuracy > 85:\n        print(\"Achievement unlocked: 70lvl Warlock!\")\n    else:\n        print(\"We need more magic! Follow instructons below\")\n    \n    print(\"-\" * 40)\n    for i in range(10):\n        if class_total[i] > 0:\n            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n                ds_test.classes[i], 100 * class_correct[i] / class_total[i],\n                np.sum(class_correct[i]), np.sum(class_total[i])))\n        else:\n            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n        \n    writer.add_scalar(\"Loss/test\", test_accuracy)\n    return test_accuracy","metadata":{"colab":{},"colab_type":"code","deletable":false,"editable":false,"id":"0iKXTHsCrYFG","nbgrader":{"grade":false,"grade_id":"2ea31c","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"2521b0c1-877e-4350-e207-075537737ea3"},"pos":22,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"4646a2","input":"dataiter = iter(trainloader)\nimages, labels = dataiter.next()\n# create grid of images\nimg_grid = torchvision.utils.make_grid(images)\n\n# show images\nmatplotlib_imshow(img_grid, one_channel=True)","pos":5,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"4a009f","input":"def model_count_params(model):\n    return np.sum([s.numel() for s in model.parameters()])","pos":11,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"4ead94","input":"# helper functions\ndef plot_classes_preds(net, images, labels, classes):\n    '''\n    Generates matplotlib Figure using a trained network, along with images\n    and labels from a batch, that shows the network's top prediction along\n    with its probability, alongside the actual label, coloring this\n    information based on whether the prediction was correct or not.\n    Uses the \"images_to_probs\" function.\n    '''\n    preds, probs = images_to_probs(net, images)\n    # plot the images in the batch, along with predicted and true labels\n    fig = plt.figure(figsize=(12, 12))\n    for idx in np.arange(16):\n        ax = fig.add_subplot(4, 4, idx+1, xticks=[], yticks=[])\n        matplotlib_imshow(images[idx], one_channel=True)\n        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n            classes[preds[idx]],\n            probs[idx] * 100.0,\n            classes[labels[idx]]),\n                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n#         plt.cla()\n    return fig\n\ndef images_to_probs(net, images):\n    '''\n    Generates predictions and corresponding probabilities from a trained\n    network and a list of images\n    '''\n    output = net(images)\n    # convert output probabilities to predicted class\n    _, preds_tensor = torch.max(output, 1)\n    preds = np.squeeze(preds_tensor.cpu().numpy())\n    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]","pos":16,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"504fe0","input":"assert accuracy(torch.ones(1000), torch.rand(1000,2)) > 0.4 \nassert accuracy(torch.ones(1000), torch.rand(1000,2)) < 0.6\nassert accuracy(torch.ones(10), torch.cat([torch.ones(10,1), torch.zeros(10,1)], dim=1)) == 0\nassert accuracy(torch.ones(10), torch.cat([torch.zeros(10,1), torch.ones(10,1)], dim=1)) == 1\n","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":true,"grade_id":"accuracy_proc","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"pos":15,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"75783e","input":"# if you get RuntimeWarning: More than 20 figures have been opened., don't worry, all figures are closed at the end of train proc\ntrain(model, writer, num_epochs=5, device=device)","pos":18,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"8f54a1","input":"train(model2, writer2, num_epochs=20, device=device)","pos":29,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"9a941b","input":"writer = SummaryWriter('runs/F-MNIST_CNN-3')","metadata":{"colab":{},"colab_type":"code","id":"I0RGtIAirYE0"},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"9aca26","input":"model_count_params(model2)","pos":28,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"9b0625","input":"\nwriter.add_scalar(\"model/size\", model_count_params(model))\nprint(\"Model size:\", model_count_params(model))\nwriter.add_graph(model, images.to(device))","pos":13,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"a0cb5a","input":"def accuracy(y_true, y_pred):\n    \"\"\"\n    calculates the accuracy of the prediction\n    y_true is N-vector of integers for N-item batch\n    y_pred is a tensor N x 10 of 10-dimensional network component output\n    \n    You have to find the number of the highest component output\n    and compare it with y_true and compute average number of exact matches.\n    \n    Returs: average number of exact matches \n    \"\"\"\n    # to find maximum item in the tensor along i dimension use .max(dim=i)\n    # to count number of matching items use '==' operator\n    # \n    # YOUR CODE HERE\n    raise NotImplementedError()\n    \n    return accuracy","metadata":{"nbgrader":{"cell_type":"code","checksum":"84d678186d79072533d189c41a113627","grade":false,"grade_id":"cell-4dc4a1834191d4dc","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":14,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"a8becf","input":"# helper function to show an image\ndef matplotlib_imshow(img, one_channel=False):\n    if one_channel:\n        img = img.mean(dim=0)\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.cpu().numpy()\n    if one_channel:\n        plt.imshow(npimg, cmap=\"Greys\")\n    else:\n        plt.imshow(np.transpose(npimg, (1, 2, 0)))","pos":4,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"b6dca5","input":"%time acc = test_model(model2, writer2);\nwriter2.close()\nassert acc > 90","metadata":{"colab":{},"colab_type":"code","deletable":false,"editable":false,"id":"B0_7ihSnrYF2","nbgrader":{"grade":true,"grade_id":"model2_accuracy","locked":true,"points":2,"schema_version":3,"solution":false,"task":false}},"pos":31,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"b999b4","input":"\n%time acc = test_model(model, writer)\nassert acc > 80\nwriter.close()\n","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":true,"grade_id":"model_accuracy","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"pos":23,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"d836e8","input":"writer2 = SummaryWriter('runs/F-MNIST_CNN-redux-1')\nwriter2.add_scalar(\"model/size\", model_count_params(model2))\nwriter2.add_graph(model2, images.to(device))\nwriter2.close()","pos":27,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"eaa745","input":"from torchvision import datasets\nimport torchvision.transforms as transforms\n\ntransform = transforms.Compose([transforms.ToTensor(),\n                                transforms.Normalize((0.5,), (0.5,)),\n                              ])\n\nds1 = datasets.FashionMNIST(\"../../data\", train=True, download=True, transform=transform)\nds_test = datasets.FashionMNIST(\"../../data\", train=False, download=True, transform=transform)\n\nds_train, ds_val = torch.utils.data.random_split(ds1, [50000, 10000])\n\ntrainloader = torch.utils.data.DataLoader(ds_train, batch_size=32,\n                                        shuffle=True, num_workers=2)\n\nvalloader = torch.utils.data.DataLoader(ds_val, batch_size=10000,\n                                        shuffle=True, num_workers=2)\n\ntestloader = torch.utils.data.DataLoader(ds_test, batch_size=10000,\n                                        shuffle=False, num_workers=2)\n\n\nprint(\"Training+Val:\", ds1,\n     \"\\nTest:\", ds_test)","pos":2,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"ef464f","input":"class Net2(nn.Module):\n    def __init__(self):\n        super(Net2, self).__init__()\n        # put all the layer initialization here\n        # YOUR CODE HERE\n        raise NotImplementedError()\n\n    def forward(self, x):\n        # pass x through all the layers\n        # YOUR CODE HERE\n        raise NotImplementedError()\n        return x\n    \nmodel2 = Net2().to(device)","metadata":{"colab":{},"colab_type":"code","id":"XRTq8rxPrYFU","nbgrader":{"cell_type":"code","checksum":"fd10b09cde41814459d26ae1b3c86773","grade":false,"grade_id":"cell-c99d6ea1d3938f86","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":25,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"f50158","input":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 4, 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(676, 100)\n        self.fc2 = nn.Linear(100, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = x.flatten(1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n    \nmodel = Net().to(device)","metadata":{"colab":{},"colab_type":"code","id":"f43dEPxzrYEb"},"pos":9,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"fb9f0b","input":"def train(model, writer, num_epochs=1, device='cpu'):\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n    criterion = nn.CrossEntropyLoss()\n\n    train_loss = []\n    test_accuracy = []\n    running_loss = 0\n    epoch_iter = tqdm.trange(num_epochs)\n    for epoch in epoch_iter:\n        for i, data in enumerate(trainloader, 0):\n\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = map(lambda x: x.to(device), data)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            if i % 100 == 99:\n                writer.add_scalar('Loss/training',\n                                running_loss / 1000,\n                                epoch * len(trainloader) + i)\n                running_loss = 0.0\n                fig = plot_classes_preds(model, inputs, labels, ds_test.classes)\n                writer.add_figure('predictions vs. actuals', fig, global_step=epoch * len(trainloader) + i)\n                plt.close(fig)\n                del fig\n\n        for X_batch, y_batch in DataLoader(ds_val, batch_size=len(ds_val)):\n            test_accuracy.append(\n                accuracy(\n                    y_batch.to(device),\n                    model(X_batch.to(device))))\n\n        writer.add_scalar('Loss/val',\n                            test_accuracy[-1],\n                            epoch)\n        epoch_iter.set_description(f\"Accuracy: {test_accuracy[-1]:.3f}\")\n    plt.close('all')","pos":17,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"fd8a23","input":"import os\nimport time\nimport tqdm\nimport torch\nimport functools\nimport numpy as np\nimport torchvision\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"colab_type":"code","id":"umUCOiHFrYDk","outputId":"4703515a-c483-4375-a7ea-1c2bf9260426"},"pos":1,"type":"cell"}
{"cell_type":"markdown","id":"16895f","input":"### Final test","metadata":{"colab_type":"text","id":"OJy3BBGKrYFE"},"pos":21,"type":"cell"}
{"cell_type":"markdown","id":"440dbd","input":"## Train it ##","metadata":{"colab_type":"text","id":"31NP8etbrYFr"},"pos":26,"type":"cell"}
{"cell_type":"markdown","id":"4a56e1","input":"## Task: improve convolution net\n\nLet's create a mini-convolutional network with an architecture like this:\n\n* 3x3 convolution with 8 filters, padding=1 and _ReLU_ activation\n* 2x2 pooling\n* 3x3 convolution with 16 filters, padding=1 and _ReLU_ activation\n* 4x4 pooling\n* flatten\n* Linear layer with ~180 input and ~100 output sizes and _ReLU_ activation\n* output linear layer\n\n\nTo find the size of the 1st linear layer you can run the cell below and \nif it throws error like this: \n\n    RuntimeError: size mismatch, m1: [32 x 784], m2: [144 x 100], \n  \nyou should change the size of the Linear layer to 784.\n\nOnce you're done, train it with __Adam__ optimizer with default params (feel free to modify the `train` procedure above).\n\n\n__TIP_OF_THE_DAY__: the number of channels must be similar to the number of classes (same order of magnitude).","metadata":{"colab_type":"text","id":"SmFLssyIrYFS"},"pos":24,"type":"cell"}
{"cell_type":"markdown","id":"59750f","input":"As in our basic tutorial, we train our model with negative log-likelihood aka crossentropy.","metadata":{"colab_type":"text","id":"Xk4XvZcBrYEk"},"pos":10,"type":"cell"}
{"cell_type":"markdown","id":"5c381c","input":"## Test it","pos":30,"type":"cell"}
{"cell_type":"markdown","id":"5cf498","input":"While the cell above is running you can open Tensorboard by a) openning new terminal, b) running from the directory of this assignment the script\n\n```\ncd mlhep2020/Section_2/2.6-CNN\n~/mlhep2020/scripts/tboard-cocalc\n```\nand c) openning TensorBoard URL in the new browser window. The URL is suggested by the script or by the cell below.","pos":19,"type":"cell"}
{"cell_type":"markdown","id":"ca6788","input":"**Fashion-MNIST** is a 10-class dataset of 28x28 grayscale images of various kind of fashion items (Zalando's article items). Named after the famous MNIST dataset with hand-written digits. Lets display a few of them.","pos":3,"type":"cell"}
{"cell_type":"markdown","id":"fac661","input":"# Building a baseline network\n\nSimple neural networks with layers applied on top of one another can be implemented either as `torch.nn.Sequential` or as a subclass of `torch.nn.Module`. \n\n__Convolutional layers__ in torch are just like all other layers, but with a specific set of parameters:\n\n__`nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3)`__\n\n__`nn.MaxPool2d(kernel_size)`__\n\nLet's start with a simple baseline:","metadata":{"colab_type":"text","id":"MM8T9MISrYEM"},"pos":8,"type":"cell"}
{"cell_type":"markdown","id":"fc0c01","input":"Checking for available GPU device.","pos":6,"type":"cell"}
{"id":0,"time":1595696280171,"type":"user"}
{"last_load":1595696280236,"type":"file"}