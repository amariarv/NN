{"backend_state":"running","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":242298880},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1595318075030,"exec_count":12,"id":"a6e919","input":"from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\n\n\n\nimport string\nimport re\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","kernel":"python3","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"2bfb8d","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":1,"start":1595318075027,"state":"done","type":"cell"}
{"cell_type":"code","end":1595318075044,"exec_count":13,"id":"be4baa","input":"SOS_token = 0\nEOS_token = 1\n\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {} # \n        self.word2count = {} # words counter\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # Count SOS and EOS\n\n\n    def addSentence(self, sentence):\n        # Add words splitting the sentence by space\n        for word in sentence.split(' '):\n            self.addWord(word)\n    \n    def addWord(self, word):\n        # Update self.word2index, self.word2count, self.n_words\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1\n","kernel":"python3","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"b7efae","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":2,"start":1595318075042,"state":"done","type":"cell"}
{"cell_type":"code","end":1595318075055,"exec_count":14,"id":"2e4704","input":"# Turn a Unicode string to plain ASCII, thanks to\n# https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n# Lowercase, trim, and remove non-letter characters\n\n\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n    return s","kernel":"python3","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"e60806","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":3,"start":1595318075052,"state":"done","type":"cell"}
{"cell_type":"code","end":1595318075069,"exec_count":15,"id":"34dc72","input":"def readLangs(lang1, lang2, reverse=False):\n    print(\"Reading lines...\")\n\n    # Read the file and split into lines\n    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n        read().strip().split('\\n')\n\n    # Split every line into pairs and normalize\n    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n\n    # Reverse pairs, make Lang instances\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        input_lang = Lang(lang2)\n        output_lang = Lang(lang1)\n    else:\n        input_lang = Lang(lang1)\n        output_lang = Lang(lang2)\n\n    return input_lang, output_lang, pairs","kernel":"python3","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"15a5d4","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":4,"start":1595318075067,"state":"done","type":"cell"}
{"cell_type":"code","end":1595318075082,"exec_count":16,"id":"56dff0","input":"MAX_LENGTH = 10\n\neng_prefixes = (\n    \"i am \", \"i m \",\n    \"he is\", \"he s \",\n    \"she is\", \"she s \",\n    \"you are\", \"you re \",\n    \"we are\", \"we re \",\n    \"they are\", \"they re \"\n)\n\n\ndef filterPair(p):\n    return len(p[0].split(' ')) < MAX_LENGTH and \\\n        len(p[1].split(' ')) < MAX_LENGTH and \\\n        p[1].startswith(eng_prefixes)\n\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]","kernel":"python3","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"49e7f8","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":5,"start":1595318075076,"state":"done","type":"cell"}
{"cell_type":"code","end":1595318098562,"exec_count":18,"id":"eef2e0","input":"def prepareData(lang1, lang2, reverse=False):\n    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n    print(\"Read %s sentence pairs\" % len(pairs))\n    pairs = filterPairs(pairs)\n    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs\n\n# Uncomment if data does not exists\n# !wget https://download.pytorch.org/tutorial/data.zip\n# !unzip data.zip > /dev/null\n\ninput_lang, output_lang, pairs = prepareData('eng', 'fra', True)\nprint(random.choice(pairs))","kernel":"python3","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"072b6c","locked":true,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"name":"stdout","text":"Reading lines...\n"},"1":{"name":"stdout","text":"Read 135842 sentence pairs\nTrimmed to 10599 sentence pairs\nCounting words...\nCounted words:\nfra 4345\neng 2803\n['il est influent .', 'he is influential .']\n"}},"pos":6,"start":1595318093704,"state":"done","type":"cell"}
{"cell_type":"code","end":1595318101533,"exec_count":19,"id":"7f4b4a","input":"def indexesFromSentence(lang, sentence):\n    # split sentence by space and convert words to indices\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)","kernel":"python3","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"d3c5ff","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":7,"start":1595318101530,"state":"done","type":"cell"}
{"cell_type":"code","end":1595318105042,"exec_count":20,"id":"02c100","input":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(input_size, hidden_size) # Special learnable layer which converts tensor of word indices to tensor of hidden size\n        self.gru = nn.GRU(hidden_size, hidden_size)\n\n    def forward(self, input, hidden):\n        embedded = self.embedding(input).view(-1, 1, self.hidden_size)\n        output = embedded\n        output, hidden = self.gru(output, hidden)\n        return output, hidden\n\n    def initHidden(self):\n\n        return torch.zeros(1, 1, self.hidden_size, device=device)","kernel":"python3","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"dbc772","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":8,"start":1595318105039,"state":"done","type":"cell"}
{"cell_type":"code","end":1595318108533,"exec_count":21,"id":"db7a49","input":"class AttnDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n        super(AttnDecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.dropout_p = dropout_p\n        self.max_length = max_length\n\n        # Define your layers here: [embeeding, 2 attention networks, dropout, RNN and linear output]\n#         self.embedding = ?\n#         self.attn = ? # Takes [input_emb, hidden_state] and returns relevance weights of encoder outputs sequence\n#         self.attn_combine = ? # Takes [input_emb, encoder_outputs_weighted_sum] and returns modified RNN input\n#         self.dropout = ?\n#         self.gru = ? # RNN (hidden_size,hidden_size)\n#         self.out = ? # RNN output of hidden_size -> token probabilites\n\n        # YOUR CODE HERE\n        #raise NotImplementedError()\n        self.embedding = nn.Embedding(self.output_size,self.hidden_size)\n        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n        self.dropout = nn.Dropout(self.dropout_p)\n        self.gru = nn.GRU(self.hidden_size,self.hidden_size)\n        self.out = nn.Linear(self.hidden_size,self.output_size)\n        \n\n    def forward(self, input, hidden, encoder_outputs):\n        embedded = self.embedding(input).view(1, 1, -1)\n        embedded = self.dropout(embedded)\n\n        attn_weights = F.softmax(\n            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1) # Weights of encoder outputs\n        attn_applied = torch.bmm(attn_weights.unsqueeze(0), # batch matrix-matrix product to get weighted sum of encoder outputs\n                                 encoder_outputs.unsqueeze(0))\n\n        output = torch.cat((embedded[0], attn_applied[0]), 1) # [input, weighted_encoder_output]\n        output = self.attn_combine(output).unsqueeze(0) # [input, weighted_encoder_output] -> [input_mod]\n\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden) # RNN on input_mod\n\n        output = F.log_softmax(self.out(output[0]), dim=1)\n        return output, hidden, attn_weights\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","kernel":"python3","metadata":{"nbgrader":{"cell_type":"code","checksum":"8fbb1b1999b2306edd31f853651ab5c3","grade":false,"grade_id":"cf9459","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":11,"start":1595318108510,"state":"done","type":"cell"}
{"cell_type":"code","end":1595318114687,"exec_count":22,"id":"9e30c6","input":"def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH,teacher_forcing_ratio=0.5):\n    encoder_hidden = encoder.initHidden()\n\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n    \n    # Initialize encoder_outputs by zeros (of shape [max_length, encoder.hidden_size])\n    # YOUR CODE HERE\n    raise NotImplementedError()\n    \n    loss = 0\n\n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(\n            input_tensor[ei], encoder_hidden)\n        # update encoder_outputs\n        # YOUR CODE HERE\n        raise NotImplementedError()\n        \n    decoder_input = torch.tensor([[SOS_token]], device=device)\n\n    decoder_hidden = encoder_hidden\n\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    for di in range(target_length):\n        # pass inputs through the decoder\n        # YOUR CODE HERE\n        raise NotImplementedError()\n        if use_teacher_forcing: # Teacher forcing: Feed the target as the next decoder input\n            decoder_input = target_tensor[di]  # Teacher forcing\n        else:                   # Without teacher forcing: use its own predictions as the next input\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach()  # detach from history as decoder input\n        loss += criterion(decoder_output, target_tensor[di])\n        # Stop if terminate token (EOS) is generated\n        if decoder_input.item() == EOS_token: # Terminate token is returned. Stop\n            break\n\n    # Perform gradient step\n    loss.backward()\n\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n    \n    return loss.item() / target_length","kernel":"python3","metadata":{"nbgrader":{"cell_type":"code","checksum":"856950bd3e2ec894507bacd8ab7ebf97","grade":false,"grade_id":"63a789","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":12,"start":1595318114685,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"03d6f5","input":"def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n\n    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n    training_pairs = [tensorsFromPair(random.choice(pairs))\n                      for i in range(n_iters)]\n    criterion = nn.NLLLoss()\n\n    for iter in range(1, n_iters + 1):\n        training_pair = training_pairs[iter - 1]\n        input_tensor = training_pair[0]\n        target_tensor = training_pair[1]\n\n        loss = train(input_tensor, target_tensor, encoder,\n                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if iter % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n                                         iter, iter / n_iters * 100, print_loss_avg))\n\n        if iter % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    showPlot(plot_losses)\n","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"8d450b","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":14,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"25574f","input":"","pos":26,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"527d2b","input":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"fc1a8f","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":15,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"6f6ec4","input":"# import torch\n\n# # Load an En-Fr Transformer model trained on WMT'14 data :\n# en2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\n\n# # Use the GPU (optional):\n# en2fr.cuda()\n\n# # Translate with beam search:\n# fr = en2fr.translate('Hello world!', beam=5)\n# assert fr == 'Bonjour à tous !'\n\n# # Manually tokenize:\n# en_toks = en2fr.tokenize('Hello world!')\n# assert en_toks == 'Hello world !'\n\n# # Manually apply BPE:\n# en_bpe = en2fr.apply_bpe(en_toks)\n# assert en_bpe == 'H@@ ello world !'\n\n# # Manually binarize:\n# en_bin = en2fr.binarize(en_bpe)\n# assert en_bin.tolist() == [329, 14044, 682, 812, 2]\n\n# # Generate five translations with top-k sampling:\n# fr_bin = en2fr.generate(en_bin, beam=5, sampling=True, sampling_topk=20)\n# assert len(fr_bin) == 5\n\n# # Convert one of the samples to a string and detokenize\n# fr_sample = fr_bin[0]['tokens']\n# fr_bpe = en2fr.string(fr_sample)\n# fr_toks = en2fr.remove_bpe(fr_bpe)\n# fr = en2fr.detokenize(fr_toks)\n# assert fr == en2fr.decode(fr_sample)","pos":25,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"77e637","input":"","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":true,"grade_id":"bb686a","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"8cc53c","input":"\ndef showAttention(input_sentence, output_words, attentions):\n    # Set up figure with colorbar\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    cax = ax.matshow(attentions.numpy(), cmap='bone')\n    fig.colorbar(cax)\n\n    # Set up axes\n    ax.set_xticklabels([''] + input_sentence.split(' ') +\n                       ['<EOS>'], rotation=90)\n    ax.set_yticklabels([''] + output_words)\n\n    # Show label at every tick\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n\n    plt.show()\n\n\ndef evaluateAndShowAttention(input_sentence):\n    output_words, attentions = evaluate(\n        encoder, decoder, input_sentence)\n    print('input =', input_sentence)\n    print('output =', ' '.join(output_words))\n    showAttention(input_sentence, output_words, attentions)\n\n\nevaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n\nevaluateAndShowAttention(\"elle est trop petit .\")\n\nevaluateAndShowAttention(\"je ne crains pas de mourir .\")\n\nevaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")","pos":23,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"b57395","input":"import time\nimport math\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"e9d29b","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"bd4fec","input":"hidden_size = 256\nencoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\ndecoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n\ntrainIters(encoder, decoder, 75000, print_every=5000)","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"2c20d9","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":18,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"ce9a00","input":"def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n    with torch.no_grad():\n        input_tensor = tensorFromSentence(input_lang, sentence)\n        input_length = input_tensor.size()[0]\n        encoder_hidden = encoder.initHidden()\n\n\n        decoded_words = []\n        # Translate the sentence. Substitute EOS_token with \"<EOS>\" and append to the end of decoded_words\n        \n        # YOUR CODE HERE\n        raise NotImplementedError()\n\n        return decoded_words, decoder_attentions[:di + 1]","metadata":{"nbgrader":{"cell_type":"code","checksum":"5167655d96c132e9b30ae5d719a217c1","grade":false,"grade_id":"ce4830","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":16,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"d93947","input":"def evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words = evaluate(encoder, decoder, pair[0])[0]\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"361d6c","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":17,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"f254df","input":"evaluateRandomly(encoder, decoder)","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"047580","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":19,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"f4bf98","input":"output_words, attentions = evaluate(\n    encoder, decoder, \"je suis trop froid .\")\nplt.matshow(attentions.numpy())","pos":22,"type":"cell"}
{"cell_type":"markdown","id":"2c894e","input":"![](https://pytorch.org/tutorials/_images/attention-decoder-network.png)","pos":10,"type":"cell"}
{"cell_type":"markdown","id":"a3211f","input":"# Transformer\nEn2Fr translation using transformer can be seen here [Pytorch examples](https://pytorch.org/hub/pytorch_fairseq_translation/)","pos":24,"type":"cell"}
{"cell_type":"markdown","id":"e5a64d","input":"## Attention decoder","pos":9,"type":"cell"}
{"cell_type":"markdown","id":"ed7265","input":"# Machine translation using RNN\nThe code is taken from [PyTorch examples](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n\n![](https://pytorch.org/tutorials/_images/seq2seq.png)","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"f9deba","input":"## Visualizing attention","pos":21,"type":"cell"}
{"end":1595318091236,"exec_count":17,"id":"f324f2","input":"#!wget https://download.pytorch.org/tutorial/data.zip\n#!unzip data.zip > /dev/null","kernel":"python3","pos":5.5,"start":1595318091234,"state":"done","type":"cell"}
{"exec_count":10,"id":"e1d5db","input":"#!wget https://download.pytorch.org/tutorial/data.zip\n#!unzip data.zip > /dev/null","kernel":"python3","metadata":{"editable":false},"output":{"0":{"name":"stdout","text":"--2020-07-21 07:41:27--  https://download.pytorch.org/tutorial/data.zip\r\nResolving download.pytorch.org (download.pytorch.org)... 13.249.71.32, 13.249.71.40, 13.249.71.29, ...\r\nConnecting to download.pytorch.org (download.pytorch.org)|13.249.71.32|:443... connected.\r\nHTTP request sent, awaiting response... "},"1":{"name":"stdout","text":"200 OK\r\nLength: 2882130 (2.7M) [application/zip]\r\nSaving to: ‘data.zip.1’\r\n\r\n\rdata.zip.1            0%[                    ]       0  --.-KB/s               "},"2":{"name":"stdout","text":"\rdata.zip.1          100%[===================>]   2.75M  --.-KB/s    in 0.07s   \r\n\r\n"},"3":{"name":"stdout","text":"2020-07-21 07:41:28 (39.8 MB/s) - ‘data.zip.1’ saved [2882130/2882130]\r\n\r\n"}},"pos":6.5,"state":"done","type":"cell"}
{"id":"893640","input":"#[batch,seq,hidden_size] #[2,10,256]\n#[seq,batch,hidden_size]","pos":7.5,"type":"cell"}
{"id":0,"time":1595316942240,"type":"user"}
{"last_load":1595316942607,"type":"file"}